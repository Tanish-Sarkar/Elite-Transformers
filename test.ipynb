{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31de040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n",
      "PyTorch: 2.7.1+cu118\n",
      "Tokens → ['hey', 'brother,', \"let's\", 'crush', 'transformers']\n",
      "Vocab  → {'hey': 0, 'crush': 1, 'brother,': 2, \"let's\": 3, 'transformers': 4}\n",
      "Embed  → tensor([[ 0.5966, -0.5076,  0.7575, -0.7036, -0.9863,  0.7856,  0.5039,  0.8090],\n",
      "        [ 0.2654, -0.7647,  0.1342,  2.2054, -0.2334, -0.7612, -0.5651,  0.7869],\n",
      "        [-0.8078,  0.3345, -1.4827,  0.7226,  0.2446,  0.1034, -0.5343, -0.4642]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Attention output → tensor([[[ 0.4500, -0.2800, -2.1500,  0.5800, -0.2600, -3.1600, -0.2600,\n",
      "          -1.4700],\n",
      "         [ 1.2700, -0.1700, -1.4200,  0.8400,  1.1400,  0.1200, -0.8300,\n",
      "           0.9900],\n",
      "         [-1.2300, -0.1400, -0.3900,  0.1300,  0.4200, -2.2800, -0.4400,\n",
      "          -0.9900]]])\n",
      "\n",
      "Q: Why divide by sqrt(d_k)?\n",
      "A: Prevents softmax saturation → gradients flow\n"
     ]
    }
   ],
   "source": [
    "# 1. GPU & PyTorch\n",
    "import torch\n",
    "print(\"GPU:\", torch.cuda.is_available())\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "\n",
    "# 2. 30-SECOND NLP Tokenizer + Embedding\n",
    "text = \"Hey brother, let's crush Transformers\"\n",
    "tokens = text.lower().split()\n",
    "vocab = {w:i for i,w in enumerate(set(tokens))}\n",
    "emb = torch.nn.Embedding(len(vocab), 8)\n",
    "print(\"Tokens →\", tokens)\n",
    "print(\"Vocab  →\", vocab)\n",
    "print(\"Embed  →\", emb(torch.tensor([0,1,2])))\n",
    "\n",
    "# 3. One-Line Attention (your RNN brain will explode)\n",
    "Q = K = V = torch.randn(1, 3, 8)          # batch=1, seq=3, dim=8\n",
    "scores = Q @ K.transpose(-2,-1) / (8**0.5)\n",
    "attn = torch.softmax(scores, dim=-1) @ V\n",
    "print(\"Attention output →\", torch.round(attn, decimals=2))\n",
    "\n",
    "# 4. Elite Probe (answer in 1 sentence)\n",
    "print(\"\\nQ: Why divide by sqrt(d_k)?\")\n",
    "print(\"A: Prevents softmax saturation → gradients flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacef68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
