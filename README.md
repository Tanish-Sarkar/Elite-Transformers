
# Elite Transformer – From Scratch to Ready for LLMs in 20 Days

**Challenge: Build deep Transformer understanding + production-grade PyTorch skills in 20 days**  
No tutorial hell. No black-box libraries. Pure implementation.

Goal: Go from RNN/Attention base → full from-scratch Transformer → GPT-like generation → ready for LLMs.

---

## 20-Day Roadmap – My Journey
# Transformer Learning Path

### Step 1: Overview & Intuition

* **Video:** [Transformer Neural Networks Explained](https://www.youtube.com/watch?v=XfpMkf4rD6E&t=40s)
* **Article:** [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) – Jay Alammar

---

### Step 2: Understanding the Paper and Transformer Architecture

#### A. Foundational Concepts
*(Together)*
* **Video:** [Attention is All You Need - Paper Explanation](https://youtu.be/bCz4OMemCcA?si=eBuvLXNfGkmNC5zz)
* **Paper:** [Attention Is All You Need (Original Research Paper)](https://arxiv.org/pdf/1706.03762)

#### B. Deep Dive & Implementation Details
*(Anyone - which every suits you)*
* **Playlist:** [Transformer Architecture Course](https://youtube.com/playlist?list=PLTl9hO2Oobd97qfWC40gOSU8C0iu0m2l4&si=IsKcaWbn4mVIGf8Z)
* **Guide:** [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/) – Harvard NLP

---

### Step 3: Code the Classical Transformer Architecture

* **Video:** [Coding a Transformer from Scratch](https://youtu.be/ISNdQcPhsts?si=O-GdzHlJ_nu4_6Ke)

---

### Step 4: Types and Variants of Transformers

* **Overview:** [Types of Transformer Models](https://medium.com/@RobuRishabh/types-of-transformer-model-1b52381fa719)
* **BERT:** [A Complete Guide to BERT (with Code)](https://towardsdatascience.com/a-complete-guide-to-bert-with-code-9f87602e4a11/)
* **GPT-1:** [Large Language Models: GPT-1](https://towardsdatascience.com/large-language-models-gpt-1-generative-pre-trained-transformer-7b895f296d3b/)
* **Project:** [Building a GPT-style Transformer from Scratch](https://medium.com/@helloitsdaksh007/building-a-gpt-style-transformer-model-from-scratch-my-deep-learning-journey-91a98af9e5d0)
* **Code:** [Code for Decoder only GPT like Tranformer](https://colab.research.google.com/drive/1MOYSipWUDvquxgbaLWsDloV0wTS-bKLR?usp=sharing)

---

### Step 5: Vision Transformer (ViT)

*(Follow in sequence)*
* **Paper:** [AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE (Original Research Paper)](https://arxiv.org/pdf/2010.11929)
1. **Video 1:** [Vision Transformer (ViT) Explained](https://youtu.be/4XgDdxpXHEQ?si=T7cQMSvf16KYnKuu)
2. **Video 2:** [Implementation of Vision Transformer](https://youtu.be/7o1jpvapaT0?si=0SKR2pu83lymgMbj)
---


## Connect & Follow

If you’re also grinding Transformers from scratch — star this repo, Follow this readme, See the code from repo for reference.

Let’s become the top 1% together.

—Tanish Sarkar
January 2026

<p align="left">
  <a href="https://www.linkedin.com/in/tanish-sarkar/" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-%230077B5.svg?logo=linkedin&logoColor=white" alt="LinkedIn">
  </a>
  <a href="https://x.com/sarkar19915" target="_blank">
    <img src="https://img.shields.io/badge/X-%23000000.svg?logo=X&logoColor=white" alt="X">
  </a>
</p>

