{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcfiKNEeKp+q9+oKZKC5vG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanish-Sarkar/Elite-Transformers/blob/main/Module1%20-%20Transformer%20Fundamentals/Embeddings_with_Toy_vocab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embeddings**"
      ],
      "metadata": {
        "id": "h9sIdMri5afA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bfOKS-WM5T9y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Basic Embedding"
      ],
      "metadata": {
        "id": "7ENwJSvC5slj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000\n",
        "d_model = 512\n",
        "embed = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "sentence_tokens = torch.randint(0, vocab_size, (4,20))\n",
        "embedded = embed(sentence_tokens)\n",
        "print(\"Embedding shape: \",embedded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u4-icCZ5pVw",
        "outputId": "3ef763aa-a8f9-4725-969d-c4d412997d9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding shape:  torch.Size([4, 20, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Simulate simple flow (no attention yet)"
      ],
      "metadata": {
        "id": "ay-9S_Gq6Ttz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_ffn = nn.Linear(d_model, vocab_size)\n",
        "output_logits = linear_ffn(embedded)\n",
        "print(\"Fake output logits shape:\", output_logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUbM7kyP6RjE",
        "outputId": "e9ee4b34-6d31-4a97-dd45-ba8a17bd9157"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake output logits shape: torch.Size([4, 20, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. NLP: Build vocab from toy corpus"
      ],
      "metadata": {
        "id": "u0cjGs437PYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toy_corpus = [\n",
        "    \"the quick brown fox jumps over the lazy dog\",\n",
        "    \"transformers are the future of nlp\",\n",
        "    \"attention is all you need\",\n",
        "    \"pytorch makes deep learning easy\"\n",
        "] * 10\n",
        "\n",
        "words = ' '.join(toy_corpus).lower().split()\n",
        "vocab = {word: idx for idx, word in enumerate(sorted(set(words)))}\n",
        "vocab_size_toy = len(vocab)\n",
        "print(\"Toy vocab size:\", vocab_size_toy)\n",
        "print(\"Sample mapping:\", list(vocab.items())[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBlxsiat6_-u",
        "outputId": "65fd2075-9e8a-49bf-c391-ef692c859409"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toy vocab size: 23\n",
            "Sample mapping: [('all', 0), ('are', 1), ('attention', 2), ('brown', 3), ('deep', 4), ('dog', 5), ('easy', 6), ('fox', 7), ('future', 8), ('is', 9)]\n"
          ]
        }
      ]
    }
  ]
}